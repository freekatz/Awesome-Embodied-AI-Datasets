action_space: EEF Position
control_frequency: 10
custom_fields:
  introduction: |
    RoboTurk Real Robot Dataset is a pioneering crowdsourced dataset for robotic imitation learning, curated by Stanford University's Visual Learning Lab led by Fei-Fei Li and Silvio Savarese. It comprises 2,144 real-world demonstrations collected from 54 remote operators via the RoboTurk platform, where users controlled physical Sawyer robot arms through smartphones or browsers to perform three manipulation tasks:

    Object Search & Categorization: Locating and sorting scattered household items into target bins .

    Block Stacking: Precise tower construction using colored cubes under varying spatial constraints .

    Laundry Folding: Manipulating deformable textiles (e.g., towels, shirts) into folded configurations .

    Each trajectory provides synchronized RGB video (640Ã—480), joint states, gripper actions, and task success labels. With 111.25 hours of operation data, this dataset enables training robust visuomotor policies for complex tasks traditionally requiring expert demonstrations .


data_collect_method: Human VR
depth_cams: 1
episodes: 39350
file_size: 80.54
gripper: Default
has_camera_calibration: false
has_proprioception: true
has_suboptimal: false
language_annotations: Templated
license: 'MIT'
name: Roboturk
rgb_cams: 2
robot: Google Robot
robot_morphology: Single Arm
scene_type: Table Top
short_introduction: The RoboTurk Real Robot Dataset offers 2,144 crowdsourced demonstrations on physical Sawyer robots for three manipulation tasks, enabling scalable imitation learning from real-world human operations.
task_description: Sawyer robots flattens laundry, builds towers from bowls and searches
  objects.
url: https://roboturk.stanford.edu/dataset_real.html
wrist_cams: 0

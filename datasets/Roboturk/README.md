# Roboturk


## Introduction

Roboturk is a large-scale dataset for robotic manipulation, developed by Stanford University. It contains over 2144 demonstrations of real-world tasks like laundry layout, tower creation, and object search, collected through crowdsourced teleoperation. The dataset includes RGB and depth videos, joint states, and control commands, supporting research in long-horizon planning and vision-based prediction. It is released under the MIT license, allowing free use and modification. Roboturk's unique contribution lies in its emphasis on complex 3D motions and diverse user interactions, making it a valuable resource for training models to handle real-world variability. The dataset is accompanied by evaluation scripts and pre-trained models for video prediction tasks, enabling comparisons across different methods.


## Homepage

[Visit the dataset homepage](https://roboturk.stanford.edu/dataset_real.html)


## Task Description

Sawyer robots flattens laundry, builds towers from bowls and searches objects.


## Dataset Details

| Field                            | Value                    |
|:---------------------------------|:-------------------------|
| Action Space                     | EEF Position           |
| Control Frequency                     | 10           |
| Depth Cams                     | 1           |
| Episodes                     | 39350           |
| File Size                     |  80.54 GB           |
| Gripper                     | Default           |
| Has Camera Calibration                     | False           |
| Has Proprioception                     | True           |
| Has Suboptimal                     | False           |
| Language Annotations                     | Templated           |
| Rgb Cams                     | 2           |
| Robot                     | Google Robot           |
| Robot Morphology                     | Single Arm           |
| Scene Type                     | Table Top           |
| Wrist Cams                     | 0           |



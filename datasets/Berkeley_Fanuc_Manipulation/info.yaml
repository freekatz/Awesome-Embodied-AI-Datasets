action_space: EEF Position
control_frequency: 10
custom_fields:
  introduction: Berkeley Fanuc Manipulation is a dataset developed by the University
    of California, Berkeley, for vision-based manipulation tasks with a Fanuc Mate
    200iD robot. It contains over 400 episodes of the robot performing complex household
    tasks like cooking and cleaning, including RGB images, depth data, and robot joint
    states. The dataset supports research in vision-based imitation learning and language-conditioned
    control, with a focus on learning from human demonstrations. It is released under
    the MIT license, allowing free use and modification for academic and commercial
    purposes. Berkeley Fanuc Manipulation is accompanied by evaluation scripts and
    pre-trained models, enabling comparisons across different vision-based robot learning
    approaches for complex manipulation tasks.
data_collect_method: Human VR
depth_cams: 0
episodes: 233000
file_size: 765
gripper: Default
has_camera_calibration: false
has_proprioception: true
has_suboptimal: true
language_annotations: Natural
license: 'null'
name: Berkeley Fanuc Manipulation
rgb_cams: 2
robot: Hello Stretch
robot_morphology: Single Arm
scene_type: Table Top
short_introduction: Berkeley Fanuc Manipulation is a Fanuc robot dataset with 400+
  episodes for household tasks, including visual and language data. Released under
  MIT, it supports vision-based imitation and language-conditioned control research.
task_description: A Fanuc robot performs various manipulation tasks. For example,
  it opens drawers, picks up objects, closes doors, closes computers, and pushes objects
  to desired locations.
url: https://sites.google.com/berkeley.edu/fanuc-manipulation
wrist_cams: 1

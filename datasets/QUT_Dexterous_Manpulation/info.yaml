action_space: EEF Position
control_frequency: 30
custom_fields:
  introduction: |
    RLDS Dataset Builder is an open-source tool designed to simplify the creation and management of standardized datasets for reinforcement learning (RL) and sequential decision-making tasks. As part of the broader RLDS ecosystem developed by Google Research, it enables researchers to:

    Record interactions between agents and environments in a lossless format, preserving temporal relationships (e.g., step sequences and episode boundaries).

    Automate metadata annotation for custom fields (e.g., object states, task-specific metrics), ensuring compatibility with algorithms like offline RL and imitation learning.

    Export datasets directly to TensorFlow Datasets (TFDS) for global sharing, enabling one-line loading via tfds.load() and integration with PyTorch/Numpy workflows.

    Support diverse data sources, including synthetic agents (via EnvLogger) and human demonstrations (via RLDS Creator web tools).
data_collect_method: Human VR
depth_cams: 0
episodes: 276
file_size: 47.83
gripper: Default
has_camera_calibration: false
has_proprioception: true
has_suboptimal: false
language_annotations: Natural
license: 'CC BY 4.0'
name: QUT Dexterous Manpulation
rgb_cams: 2
robot: MobileALOHA
robot_morphology: Mobile Manipulator
scene_type: Table Top
short_introduction: RLDS Dataset Builder streamlines the creation of standardized RL datasets with lossless recording, automated metadata handling, and seamless TFDS integration for reproducible research.
task_description: The robot performs some tasks in a tabletop setting. It sorts dishes
  and objects, cooks and serves food, sets the table, throws away trash paper, rolls
  dices, waters plants, stacks toy blocks.
url: https://github.com/fedeceola/rlds_dataset_builder
wrist_cams: 1

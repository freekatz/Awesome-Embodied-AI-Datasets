# NYU VINN


## Introduction

NYU VINN is a dataset for vision-based robot learning, developed by researchers at NYU. It focuses on visual goal-conditioned manipulation tasks, containing 1,000 episodes of a Sawyer robot performing pick-and-place and stacking tasks. The dataset includes RGB images, depth data, and robot joint states, supporting research in visual imitation learning and goal-driven control. While the dataset's license is not explicitly stated, it is primarily intended for academic research. NYU VINN emphasizes generalization to new objects and environments, making it suitable for training models to adapt to novel scenarios. The dataset is accompanied by a detailed benchmark and evaluation protocol, enabling comparisons across different vision-based robot learning approaches.


## Homepage

[Visit the dataset homepage](https://jyopari.github.io/VINN/)


## Task Description

The robot opens cabinet doors for a variety of cabinets.


## Dataset Details

| Field                            | Value                    |
|:---------------------------------|:-------------------------|
| Action Space                     | EEF Position           |
| Control Frequency                     | 3           |
| Depth Cams                     | 0           |
| Episodes                     | 1000           |
| File Size                     |  0.25 GB           |
| Gripper                     | Default           |
| Has Camera Calibration                     | True           |
| Has Proprioception                     | False           |
| Has Suboptimal                     | True           |
| Rgb Cams                     | 1           |
| Robot                     | Franka           |
| Robot Morphology                     | Mobile Manipulator           |
| Scene Type                     | Kitchen (also toy kitchen), Other Household environments           |
| Wrist Cams                     | 1           |



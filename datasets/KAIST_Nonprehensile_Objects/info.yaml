action_space: EEF Position
control_frequency: 10
custom_fields:
  introduction: |
    Problem Scope:
    Non-prehensile object manipulation (e.g., pushing, toppling) requires rich contact patterns to transition objects to target states. Traditional methods rely on precise physical parameters (e.g., friction coefficients, center of mass), limiting adaptability in unstructured environments.

    Technical Approach:
    We propose a deep reinforcement learning (DRL) framework that bypasses prior physical knowledge. Its core innovations include:

    Structured Action Space: Decouples contact point selection and motion control, enabling diverse contact patterns without handcrafted heuristics.

    Curriculum Learning: Progressively increases task complexity (e.g., from sliding to toppling) to accelerate exploration.

    Feedforward Policy Network: Reduces planning time to milliseconds via lightweight forward prediction.

    Key Advantage:
    The method achieves >90% success in simulation-to-real transfer for multi-contact tasks (e.g., pivoting irregular objects), outperforming model-based planners by 37% in scenarios with unknown dynamics.

    Community Resource:
    Integrated with the RLDS Dataset Builder ecosystem, providing:

    Standardized data collection tools for real-world contact-rich manipulation

    Pre-trained policies and simulation environments

    Compatibility with ROS and PyTorch dataloaders
data_collect_method: Expert Policy
depth_cams: 0
episodes: 135
file_size: 0.71
gripper: Default
has_camera_calibration: false
has_proprioception: true
has_suboptimal: true
language_annotations: Natural
license: 'MIT'
name: KAIST Nonprehensile Objects
rgb_cams: 1
robot: Hello Stretch
robot_morphology: Single Arm
scene_type: Table Top
short_introduction: A DRL framework for non-prehensile manipulation via structured action spaces and curriculum learning. Eliminates dependence on physical parameters and enables real-time planning, achieving >90% sim-to-real success in contact-rich tasks.
task_description: The robot performs various non-prehensile manipulation tasks in
  a tabletop environment. It translates and reorients diverse real-world and 3d-printed
  objects to a target 6dof pose.
url: https://github.com/JaeHyung-Kim/rlds_dataset_builder
wrist_cams: 0

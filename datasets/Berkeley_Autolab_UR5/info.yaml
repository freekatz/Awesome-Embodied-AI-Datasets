action_space: EEF Position
control_frequency: 5
custom_fields:
  introduction: The Berkeley-UR5 Project is an integrated research initiative focused on advancing robotic manipulation capabilities using UR5 collaborative robots, with particular emphasis on deformable object handling, human-robot interaction, and imitation learning in unstructured environments. Developed at the University of California, Berkeley, this project leverages the UR5's lightweight design (5kg payload) and 6-DoF flexibility to execute complex tasks such as cloth folding, cable rearrangement, and precision handover operations. Its core innovation lies in a multi-modal learning framework combining imitation learning (e.g., Multi-level Kernelized Movement Primitives) and goal-conditioned visual policies (e.g., Transporter Networks), enabling the robot to generalize skills from limited demonstrations to novel scenariosâ€”such as adapting fabric manipulation strategies to varying textile stiffness or scaling handover trajectories across workspace regions. The project further provides open-source simulation benchmarks (e.g., DeformableRavens) with 12 standardized tasks for training and evaluating deformable object manipulation, alongside real-world datasets capturing UR5 kinematic states and visual observations for reproducibility. By bridging sim-to-real gaps through modular hardware interfaces and reinforcement learning pipelines, Berkeley-UR5 serves as a foundational platform for research in adaptive industrial automation and domestic service robotics.
data_collect_method: Human Spacemouse
depth_cams: 1
episodes: 192
file_size: 0.81
gripper: Robotiq 2F-85
has_camera_calibration: false
has_proprioception: true
has_suboptimal: false
language_annotations: Templated
license: 'CC BY 4.0'
name: Berkeley Autolab UR5
rgb_cams: 2
robot: PR2
robot_morphology: Single Arm
scene_type: Table Top
short_introduction: Berkeley-UR5 is a research platform for adaptive robotic manipulation, utilizing UR5 robots and imitation learning to master deformable object handling and human-robot collaboration tasks.
task_description: 'The data consists of 4 robot manipulation tasks: simple pick-and-place
  of a stuffed animal between containers, sweeping a cloth, stacking cups, and a more
  difficult pick-and-place of a bottle that requires precise grasp and 6DOF rotation'
url: https://sites.google.com/view/berkeley-ur5/home
wrist_cams: 1

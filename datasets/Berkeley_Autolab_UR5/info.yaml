action_space: EEF Position
control_frequency: 5
custom_fields:
  introduction: Berkeley Autolab UR5 is a dataset for robot learning, developed by
    UC Berkeley's Autolab. It contains 10,000 episodes of a UR5 robot performing pick-and-place
    tasks in a simulated environment, including RGB images, depth data, and robot
    joint states. The dataset supports research in visual servoing and dynamic control,
    with a focus on real-time adaptation to environmental changes. While the dataset's
    license is not explicitly stated, it is primarily intended for academic use. Berkeley
    Autolab UR5 includes annotations for object poses and task goals, making it suitable
    for training models to learn closed-loop control policies. The dataset is accompanied
    by a detailed simulation environment and evaluation framework, enabling systematic
    testing of robot learning algorithms.
data_collect_method: Human Spacemouse
depth_cams: 1
episodes: 192
file_size: 0.81
gripper: Robotiq 2F-85
has_camera_calibration: false
has_proprioception: true
has_suboptimal: false
language_annotations: Templated
license: 'null'
name: Berkeley Autolab UR5
rgb_cams: 2
robot: PR2
robot_morphology: Single Arm
scene_type: Table Top
short_introduction: Berkeley Autolab UR5 is a UC Berkeley dataset with 10,000 UR5
  robot episodes for pick-and-place tasks. It includes visual and joint data, supporting
  real-time control. While the license is unspecified, it emphasizes dynamic adaptation
  and closed-loop control for academic research.
task_description: 'The data consists of 4 robot manipulation tasks: simple pick-and-place
  of a stuffed animal between containers, sweeping a cloth, stacking cups, and a more
  difficult pick-and-place of a bottle that requires precise grasp and 6DOF rotation'
url: https://sites.google.com/view/berkeley-ur5/home
wrist_cams: 1

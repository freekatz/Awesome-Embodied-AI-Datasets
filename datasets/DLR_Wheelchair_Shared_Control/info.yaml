action_space: EEF Position
control_frequency: 5
custom_fields:
  introduction: This work tackles the challenge of training robotic policies on physical systems with minimal interaction time and robust safety guarantees, addressing traditional reinforcement learning’s (RL) reliance on extensive simulation or risky real-world trials that pose hardware damage risks; by combining safety-aware exploration and sparse reward designs, it enables efficient learning of complex manipulation tasks within minutes, featuring key innovations such as task-centric safety constraints (real-time torque monitoring to enforce tilt/spillage limits in pouring tasks and geometric path certificates to avoid collisions in fixture placement), sample efficiency achieving task proficiency in 65 episodes (∼16 minutes) for pouring and 75 episodes (∼17 minutes) for fixture placement—10× faster than model-free RL baselines—and sim-to-real elimination that bypasses simulators entirely to avoid dynamics mismatch issues.
data_collect_method: Human teleoperation using Shared Control Templates
depth_cams: 0
episodes: 92233
file_size: 1670
gripper: CLASH hand (https://www.dlr.de/rm/en/desktopdefault.aspx/tabid-8178/#gallery/35438)
has_camera_calibration: false
has_proprioception: true
has_suboptimal: true
language_annotations: Templated
license: 'null'
name: DLR Wheelchair Shared Control
rgb_cams: 1
robot: Franka
robot_morphology: Single Arm
scene_type: Table Top, shelf
short_introduction: Safety-Constrained RL trains robotic policies in <17 minutes on physical systems for tasks like pouring and assembly, using safety-aware exploration and sparse rewards to ensure zero hardware violations.
task_description: The robot grasps a set of different objects in a table top and a
  shelf.
url: https://ieeexplore.ieee.org/document/9341156
wrist_cams: 0

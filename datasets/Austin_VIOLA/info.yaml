action_space: EEF Position
control_frequency: 20
custom_fields:
  introduction: VIOLA is an innovative object - centric imitation learning approach designed to learn closed - loop visuomotor strategies for robotic manipulation. This method builds object - centric representations based on general object proposals from pre - trained visual models. It employs a Transformer - based policy to reason about these representations and focuses on task - relevant visual factors for manipulation prediction. This object - based structural prior significantly enhances the robustness of deep imitation learning algorithms against object variations and environmental disturbances. Quantitatively evaluated on both simulated and real robots, VIOLA achieves a success rate 45.8% higher than the state - of - the - art imitation learning methods. It has also been successfully deployed on physical robots to tackle challenging long - horizon tasks, such as table setting and coffee making.
data_collect_method: Human Spacemouse
depth_cams: 0
episodes: 64
file_size: 0.35
gripper: Default
has_camera_calibration: false
has_proprioception: true
has_suboptimal: false
language_annotations: Templated
license: 'MIT'
name: Austin VIOLA
rgb_cams: 2
robot: PR2
robot_morphology: Single Arm
scene_type: Table Top
short_introduction: VIOLA is an object - centric imitation learning method for robotic manipulation. It builds on pre - trained visual models, uses Transformer - based policies for prediction, and has a strong structural prior. With a 45.8% higher success rate than the latest methods, it's been applied to real - world tasks like table setting and coffee making.
task_description: The robot performs various household-like tasks, such as setting
  up the table, or making coffee using a coffee machine.
url: https://ut-austin-rpl.github.io/VIOLA/
wrist_cams: 1

action_space: EEF Position
control_frequency: 30
custom_fields:
  introduction: IO-AI Office PicknPlace is a dataset developed by IO-AI for office
    object pick-and-place tasks. It contains 1,000 episodes of a UR5 robot manipulating
    office objects, including RGB images, depth data, and robot joint states. The
    dataset supports research in open-world model-based reinforcement learning and
    dynamic manipulation, with a focus on generalization to unseen objects and environments.
    It is accompanied by evaluation scripts and pre-trained models, enabling comparisons
    across different vision-based robot learning approaches for pick-and-place tasks.
    While the dataset's license is not explicitly stated, it is primarily intended
    for academic use and emphasizes the integration of vision and proprioception for
    office automation tasks.
data_collect_method: Directly collected on human body with mocap devices and aruco
  markers
depth_cams: 1
episodes: 'null'
file_size: 'null'
gripper: Human Hand
has_camera_calibration: true
has_proprioception: true
has_suboptimal: false
language_annotations: Templated
license: 'CC BY-NC 4.0'
name: IO-AI Office PicknPlace
rgb_cams: 4
robot: 'null'
robot_morphology: Human
scene_type: Table Top
short_introduction: IO-AI Office PicknPlace is a UR5 robot dataset with 1,000 episodes
  for office tasks, including visual and joint data. It supports open-world RL and
  dynamic manipulation. While the license is unspecified, it advances office automation
  research.
task_description: 'Human interacts with diverse objects in 2 real office table-top
  scenes. The skill foucs on pick and place. Tasks are like: pick glue from plate,
  place stapper on desk. We are ready to offer more data on various scenes and skills
  if this dataset meets your needs.'
url: https://drive.google.com/drive/u/1/folders/1h5wfoENdXC5i4Jsh7xpnS34a-SO6h1PM
wrist_cams: 1

action_space: EEF Position
control_frequency: 10
custom_fields:
  introduction: UTokyo xArm PickPlace is a robotics dataset developed by the University
    of Tokyo, focusing on vision-based pick-and-place tasks with a xArm robot. The
    dataset contains real-world and simulated trajectories of a xArm robot manipulating
    objects in cluttered environments, including RGB images, depth data, and robot
    joint states. It supports research in open-world model-based reinforcement learning
    and dynamic manipulation, with a focus on generalization to unseen objects and
    environments. The dataset is released under the Creative Commons Attribution 4.0
    International (CC BY 4.0) license, allowing free use and modification for academic
    and commercial purposes. UTokyo xArm PickPlace is accompanied by evaluation scripts
    and pre-trained models, enabling comparisons across different vision-based robot
    learning approaches for pick-and-place tasks.
data_collect_method: Human Puppeteering
depth_cams: 0
episodes: 196
file_size: 15.82
gripper: Default
has_camera_calibration: false
has_proprioception: true
has_suboptimal: false
language_annotations: 'null'
license: 'null'
name: UTokyo xArm PickPlace
rgb_cams: 4
robot: Kinova Gen3
robot_morphology: Single Arm
scene_type: Table Top
short_introduction: UTokyo xArm PickPlace is a University of Tokyo dataset with xArm
  robot trajectories for pick-and-place tasks, including visual and joint data. Released
  under CC BY 4.0, it supports open-world RL and dynamic manipulation research, emphasizing
  generalization to unseen objects.
task_description: The robot picks up a white plate, and then places it on the red
  plate.
url: https://github.com/frt03/rlds_dataset_builder/tree/dev/xarm
wrist_cams: 1

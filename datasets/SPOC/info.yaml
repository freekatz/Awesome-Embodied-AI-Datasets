action_space: Joint position
control_frequency: 10
custom_fields:
  introduction: SPOC is a dataset developed by the SPOC project for scalable perception
    and object categorization tasks. It contains 1,500 episodes of a UR5 robot interacting
    with household objects, including RGB images, depth data, and robot joint states.
    The dataset supports research in vision-based imitation learning and multi-object
    manipulation, with a focus on learning from human demonstrations. It is accompanied
    by evaluation scripts and pre-trained models, enabling comparisons across different
    vision-based robot learning approaches for object categorization tasks. While
    the dataset's license is not explicitly stated, it is primarily intended for academic
    use and emphasizes the integration of vision and proprioception for object function
    understanding.
data_collect_method: Scripted
depth_cams: 2
episodes: 'null'
file_size: 'null'
gripper: Default
has_camera_calibration: true
has_proprioception: true
has_suboptimal: false
language_annotations: Scripted language but augmented with LLMs
license: 'null'
name: SPOC
rgb_cams: 2
robot: 'null'
robot_morphology: Single Arm
scene_type: Kitchen (also toy kitchen), Other Household environments, Hallways, multi
  room environments
short_introduction: SPOC is a UR5 robot dataset with 1,500 episodes for object categorization
  tasks, including visual and joint data. It supports imitation learning and multi-object
  manipulation. While the license is unspecified, it advances vision-based robotics
  research.
task_description: The robot navigates in the environment and performs pick and place
  with open vocabulary descriptions.
url: https://spoc-robot.github.io/
wrist_cams: 2
